# ðŸ©º Medical Chatbot with RAG

A Flask-based medical question-answering chatbot leveraging Retrieval-Augmented Generation (RAG) to provide concise, context-aware information on medical conditions, including prevention and medication advice.

---

## Architecture - 

![alt text](Backend.jpeg)
![alt text](Frontend.jpeg)

---

## âœ¨ Features

* **Intelligent Q&A:** Answers medical queries using a Large Language Model (LLM) powered by retrieved context.
* **Retrieval-Augmented Generation (RAG):** Enhances LLM responses by fetching relevant information from a custom knowledge base.
* **Custom Knowledge Base:** Indexes and stores medical data from PDF documents.
* **Vector Database:** Utilizes Pinecone for efficient storage and semantic search of high-dimensional text embeddings.
* **HuggingFace Embeddings:** Employs `sentence-transformers` models (`all-MiniLM-L6-v2`) for generating robust text embeddings.
* **LangChain Integration:** Orchestrates the RAG pipeline, connecting LLM, embeddings, and vector store components.
* **Flexible LLM Backend:** Configured to use **Google Gemma 3n 2B (free)** via the **OpenRouter.ai API gateway**.
* **Web Interface:** User-friendly chat interface built with Flask, HTML, and CSS.

---

## ðŸš€ Technologies Used

* **Python**
* **Flask:** Web Framework
* **LangChain:** LLM Orchestration Framework
* **HuggingFace Transformers/Sentence-Transformers:** Embeddings
* **Pinecone:** Vector Database
* **OpenRouter.ai:** LLM API Gateway
* **pypdf:** PDF Document Loading
* **python-dotenv:** Environment Variable Management
* **HTML, CSS, JavaScript:** Frontend

---

## ðŸ“ Project Structure

```
Medical_Chatbot/
â”œâ”€â”€ app.py                  # Main Flask application with chatbot logic
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # HTML for the chat interface
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css           # CSS for styling the web interface
â”œâ”€â”€ data/                   # Directory to store input PDF documents
â”‚   â””â”€â”€ your_medical_docs.pdf
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ helper.py           # Contains functions for PDF loading, text splitting, embeddings
â”‚   â”œâ”€â”€ promot.py           # Likely contains the system_prompt definition
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .env                    # Environment variables (API keys) - NOT committed to Git!
â”œâ”€â”€ requirements.txt        # Python package dependencies
â”œâ”€â”€ store_index.py          # Script to process data and populate Pinecone index
â”œâ”€â”€ setup.py                # Python package setup file
â”œâ”€â”€ README.md               # This file
â””â”€â”€ ... (other project files)
```

---

## ðŸ› ï¸ Setup and Installation

Follow these steps to get your Medical Chatbot up and running on your local machine.

### 1. Clone the Repository

First, clone the project repository to your local machine:

```bash
git clone [https://github.com/Anugrah0619/Medical_Chatbot.git](https://github.com/Anugrah0619/Medical_Chatbot.git)
cd Medical_Chatbot
```

---

## 2. Create and Activate Conda Environment

It's highly recommended to use a Conda virtual environment to manage dependencies:

```bash
conda create -n medbot python=3.10 -y
conda activate medbot
```

---

## 3. Install Required Libraries

Install all necessary Python packages using `pip`:

```bash
pip install -r requirements.txt
```

---

## 4. Configure API Keys

Create a `.env` file in the root directory of your project (`Medical_Chatbot/`). This file will securely store your API keys.

Add your API keys to the `.env` file like this:

```env
PINECONE_API_KEY="your_pinecone_api_key_here"
OPENROUTER_API_KEY="your_openrouter_api_key_here"
```

> ðŸ”’ **Do not share your `.env` file publicly.**

---

## 5. Prepare Medical Data (PDFs)

Place your medical PDF documents in a folder named `data/` inside the root directory:

```
Medical_Chatbot/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ example1.pdf
â”‚   â”œâ”€â”€ example2.pdf
```

---

## 6. Initialize and Populate Pinecone Index

This step processes your PDF data, generates embeddings, and uploads them to your Pinecone vector database. Run this once to set up your knowledge base.

```bash
python store_index.py
```

This script will:
- Initialize the Pinecone client
- Create the `medicalbot` index if it doesnâ€™t exist (`dimension=384`, `metric=cosine`)
- Chunk and embed PDFs using `all-MiniLM-L6-v2`
- Upload embeddings to Pinecone

---

## 7. Run the Flask Web Application

Once the Pinecone index is populated, you can launch the chatbot:

```bash
python app.py
```

---

## 8. Access the Chatbot

After starting the Flask app, open your browser and visit:

```
http://127.0.0.1:5000/
```

Youâ€™ll see the chatbot interface where you can ask questions related to the uploaded medical PDFs.
